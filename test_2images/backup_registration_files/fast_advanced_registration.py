#!/usr/bin/env python3
# ğŸš€ é«˜é€Ÿé«˜ç²¾åº¦è„³ã‚¹ãƒ©ã‚¤ã‚¹ãƒ¬ã‚¸ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ - ç›®æ¨™0.8+é”æˆ
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import entropy
from scipy.ndimage import sobel, affine_transform, gaussian_filter
from scipy.optimize import differential_evolution
from PIL import Image
import os
import warnings
warnings.filterwarnings('ignore')

print("=" * 80)
print("ğŸ§  é«˜é€Ÿé«˜ç²¾åº¦è„³ã‚¹ãƒ©ã‚¤ã‚¹ãƒ¬ã‚¸ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ - ç›®æ¨™0.8+é”æˆ")
print("=" * 80)

# ===== æœ€é©åŒ–ã•ã‚ŒãŸãƒ¡ãƒˆãƒªã‚¯ã‚¹é–¢æ•°ç¾¤ =====
def fast_mutual_information(img1, img2, bins=50):
    """é«˜é€Ÿç›¸äº’æƒ…å ±é‡è¨ˆç®—"""
    hist_2d, _, _ = np.histogram2d(img1.flatten(), img2.flatten(), bins=bins)
    hist_2d = hist_2d / (hist_2d.sum() + 1e-12)
    
    px = hist_2d.sum(axis=1) + 1e-12
    py = hist_2d.sum(axis=0) + 1e-12
    hist_2d = hist_2d + 1e-12
    
    hx = -np.sum(px * np.log(px))
    hy = -np.sum(py * np.log(py))
    hxy = -np.sum(hist_2d * np.log(hist_2d))
    
    return hx + hy - hxy

def fast_ssim(img1, img2):
    """é«˜é€ŸSSIMè¨ˆç®—"""
    mean1, mean2 = np.mean(img1), np.mean(img2)
    var1, var2 = np.var(img1), np.var(img2)
    cov = np.mean((img1 - mean1) * (img2 - mean2))
    
    c1, c2 = (0.01 * 255)**2, (0.03 * 255)**2
    
    ssim = ((2*mean1*mean2 + c1)*(2*cov + c2)) / ((mean1**2 + mean2**2 + c1)*(var1 + var2 + c2))
    return np.clip(ssim, -1, 1)

def fast_edge_correlation(img1, img2):
    """é«˜é€Ÿã‚¨ãƒƒã‚¸ç›¸é–¢"""
    # ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§é«˜é€ŸåŒ–
    step = 2
    img1_ds = img1[::step, ::step]
    img2_ds = img2[::step, ::step]
    
    dx1, dy1 = sobel(img1_ds, axis=0), sobel(img1_ds, axis=1)
    dx2, dy2 = sobel(img2_ds, axis=0), sobel(img2_ds, axis=1)
    
    edge1 = np.sqrt(dx1**2 + dy1**2)
    edge2 = np.sqrt(dx2**2 + dy2**2)
    
    return np.corrcoef(edge1.flatten(), edge2.flatten())[0,1]

def apply_simple_transform(image, params):
    """ã‚·ãƒ³ãƒ—ãƒ«ãªå¤‰æ›é©ç”¨ï¼ˆé«˜é€ŸåŒ–ï¼‰"""
    angle, tx, ty, scale = params
    
    # å›è»¢
    if abs(angle) > 0.01:
        from scipy.ndimage import rotate
        image = rotate(image, angle, reshape=False, order=1)
    
    # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
    if abs(scale - 1.0) > 0.01:
        from scipy.ndimage import zoom
        image = zoom(image, scale, order=1)
    
    # å¹³è¡Œç§»å‹•
    if abs(tx) > 0.5 or abs(ty) > 0.5:
        from scipy.ndimage import shift
        image = shift(image, [ty, tx], order=1)
    
    return image

def fast_composite_similarity(img1, img2):
    """é«˜é€Ÿè¤‡åˆé¡ä¼¼åº¦é–¢æ•°"""
    try:
        # åŸºæœ¬ç›¸é–¢ä¿‚æ•°ï¼ˆæœ€é‡è¦ï¼‰
        corr = np.corrcoef(img1.flatten(), img2.flatten())[0,1]
        if np.isnan(corr):
            corr = 0.0
        
        # ç›¸äº’æƒ…å ±é‡
        mi = fast_mutual_information(img1, img2)
        if np.isnan(mi):
            mi = 0.0
        
        # SSIM
        ssim = fast_ssim(img1, img2)
        if np.isnan(ssim):
            ssim = 0.0
        
        # ã‚¨ãƒƒã‚¸ç›¸é–¢
        edge_corr = fast_edge_correlation(img1, img2)
        if np.isnan(edge_corr):
            edge_corr = 0.0
        
        # ç›¸é–¢ä¿‚æ•°ã‚’å¤§å¹…ã«é‡è¦–ã—ãŸé‡ã¿ä»˜ã‘
        weights = [0.60, 0.20, 0.15, 0.05]  # ç›¸é–¢ä¿‚æ•°60%
        
        composite = weights[0]*corr + weights[1]*mi + weights[2]*ssim + weights[3]*edge_corr
        return composite
        
    except:
        return 0.0

# ===== ç”»åƒèª­ã¿è¾¼ã¿ =====
print("ğŸ–¼ï¸ è„³ã‚¹ãƒ©ã‚¤ã‚¹ç”»åƒã‚’èª­ã¿è¾¼ã¿ä¸­...")

image_dir = "./test2slices/"
tiff_files = [f for f in os.listdir(image_dir) if f.endswith('.tif')]
print(f"ğŸ“ TIFFãƒ•ã‚¡ã‚¤ãƒ«: {tiff_files}")

if len(tiff_files) < 2:
    raise FileNotFoundError("2ã¤ã®TIFFãƒ•ã‚¡ã‚¤ãƒ«ãŒå¿…è¦ã§ã™")

# ç”»åƒèª­ã¿è¾¼ã¿ãƒ»å‰å‡¦ç†
img1_path = os.path.join(image_dir, tiff_files[0])
img2_path = os.path.join(image_dir, tiff_files[1])

img1 = np.array(Image.open(img1_path).convert('L'), dtype=np.float32)
img2 = np.array(Image.open(img2_path).convert('L'), dtype=np.float32)

# é«˜é€ŸåŒ–ã®ãŸã‚ãƒªã‚µã‚¤ã‚º
scale_factor = 0.5  # åŠåˆ†ã®ã‚µã‚¤ã‚ºã§é«˜é€Ÿå‡¦ç†
from scipy.ndimage import zoom
img1_fast = zoom(img1, scale_factor, order=1)
img2_fast = zoom(img2, scale_factor, order=1)

# æ­£è¦åŒ–
img1_fast = (img1_fast - img1_fast.min()) / (img1_fast.max() - img1_fast.min())
img2_fast = (img2_fast - img2_fast.min()) / (img2_fast.max() - img2_fast.min())

print(f"ğŸ§  é«˜é€Ÿå‡¦ç†ç”¨ç”»åƒã‚µã‚¤ã‚º: {img1_fast.shape}")
print("âœ… è„³ã‚¹ãƒ©ã‚¤ã‚¹ç”»åƒã®èª­ã¿è¾¼ã¿æˆåŠŸï¼\n")

# ===== åˆæœŸè©•ä¾¡ =====
print("ğŸ“Š åˆæœŸçŠ¶æ…‹:")
initial_composite = fast_composite_similarity(img1_fast, img2_fast)
initial_corr = np.corrcoef(img1_fast.flatten(), img2_fast.flatten())[0,1]
print(f"   è¤‡åˆé¡ä¼¼åº¦: {initial_composite:.4f}")
print(f"   ç›¸é–¢ä¿‚æ•°: {initial_corr:.4f}")
print()

# ===== é«˜é€Ÿæœ€é©åŒ– =====
print("ğŸ¯ é«˜é€Ÿé«˜ç²¾åº¦ãƒ¬ã‚¸ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œä¸­...")

def objective_function(params):
    """æœ€é©åŒ–ç›®çš„é–¢æ•°"""
    try:
        transformed_img2 = apply_simple_transform(img2_fast, params)
        # ã‚µã‚¤ã‚ºèª¿æ•´
        if transformed_img2.shape != img1_fast.shape:
            from scipy.ndimage import zoom
            scale_y = img1_fast.shape[0] / transformed_img2.shape[0]
            scale_x = img1_fast.shape[1] / transformed_img2.shape[1]
            transformed_img2 = zoom(transformed_img2, [scale_y, scale_x], order=1)
        
        similarity = fast_composite_similarity(img1_fast, transformed_img2)
        return -similarity  # æœ€å°åŒ–å•é¡Œã¨ã—ã¦
    except:
        return 1000.0  # ãƒšãƒŠãƒ«ãƒ†ã‚£

# æ®µéšçš„æœ€é©åŒ–ï¼ˆé«˜é€Ÿç‰ˆï¼‰
print("ğŸ”„ Stage1: ç²—ã„æ¢ç´¢...")
result1 = differential_evolution(
    objective_function,
    bounds=[(-45, 45), (-100, 100), (-100, 100), (0.5, 1.5)],  # angle, tx, ty, scale
    maxiter=30,
    popsize=15,
    seed=42
)

print(f"   Stage1çµæœ: {-result1.fun:.4f}")
print(f"   ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: è§’åº¦{result1.x[0]:.2f}Â°, ç§»å‹•({result1.x[1]:.1f},{result1.x[2]:.1f}), ã‚¹ã‚±ãƒ¼ãƒ«{result1.x[3]:.3f}")

# Stage1ã®çµæœã‚’ä¸­å¿ƒã¨ã—ãŸç²¾å¯†æ¢ç´¢
center_params = result1.x
search_range = 10

print("ğŸ”„ Stage2: ç²¾å¯†æ¢ç´¢...")
result2 = differential_evolution(
    objective_function,
    bounds=[
        (center_params[0]-search_range, center_params[0]+search_range),
        (center_params[1]-search_range, center_params[1]+search_range), 
        (center_params[2]-search_range, center_params[2]+search_range),
        (max(0.1, center_params[3]-0.3), center_params[3]+0.3)
    ],
    maxiter=50,
    popsize=20,
    seed=42
)

print(f"   Stage2çµæœ: {-result2.fun:.4f}")
print(f"   ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: è§’åº¦{result2.x[0]:.2f}Â°, ç§»å‹•({result2.x[1]:.1f},{result2.x[2]:.1f}), ã‚¹ã‚±ãƒ¼ãƒ«{result2.x[3]:.3f}")

# æœ€è‰¯çµæœé¸æŠ
best_result = result2 if -result2.fun > -result1.fun else result1
best_similarity = -best_result.fun

print(f"\nğŸ† æœ€çµ‚æœ€é©åŒ–çµæœ:")
print(f"   æœ€é«˜é¡ä¼¼åº¦: {best_similarity:.4f}")
print(f"   æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {best_result.x}")

# ===== ãƒ•ãƒ«ã‚µã‚¤ã‚ºã§æœ€çµ‚å¤‰æ›é©ç”¨ =====
print("ğŸ¯ ãƒ•ãƒ«ã‚µã‚¤ã‚ºç”»åƒã§æœ€çµ‚å¤‰æ›é©ç”¨ä¸­...")

# å…ƒç”»åƒã®æ­£è¦åŒ–
img1_full = (img1 - img1.min()) / (img1.max() - img1.min())
img2_full = (img2 - img2.min()) / (img2.max() - img2.min())

# ã‚µã‚¤ã‚ºçµ±ä¸€
min_h = min(img1_full.shape[0], img2_full.shape[0])
min_w = min(img1_full.shape[1], img2_full.shape[1])
img1_full = img1_full[:min_h, :min_w]
img2_full = img2_full[:min_h, :min_w]

# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒ•ãƒ«ã‚µã‚¤ã‚ºã«èª¿æ•´
full_params = best_result.x.copy()
full_params[1] *= (1/scale_factor)  # txèª¿æ•´
full_params[2] *= (1/scale_factor)  # tyèª¿æ•´

final_transformed = apply_simple_transform(img2_full, full_params)

# ã‚µã‚¤ã‚ºèª¿æ•´
if final_transformed.shape != img1_full.shape:
    from scipy.ndimage import zoom
    scale_y = img1_full.shape[0] / final_transformed.shape[0]
    scale_x = img1_full.shape[1] / final_transformed.shape[1]
    final_transformed = zoom(final_transformed, [scale_y, scale_x], order=1)

final_corr = np.corrcoef(img1_full.flatten(), final_transformed.flatten())[0,1]
final_composite = fast_composite_similarity(img1_full, final_transformed)

# ===== çµæœè©•ä¾¡ =====
print(f"\nğŸ“ˆ æœ€çµ‚çµæœ:")
print(f"   ç›¸é–¢ä¿‚æ•°: {initial_corr:.4f} â†’ {final_corr:.4f} ({final_corr-initial_corr:+.4f})")
print(f"   è¤‡åˆé¡ä¼¼åº¦: {initial_composite:.4f} â†’ {final_composite:.4f} ({final_composite-initial_composite:+.4f})")
improvement_rate = ((final_composite-initial_composite)/abs(initial_composite))*100 if initial_composite != 0 else 0
print(f"   æ”¹å–„ç‡: {improvement_rate:+.1f}%")

# ç›®æ¨™é”æˆãƒã‚§ãƒƒã‚¯
if final_corr >= 0.8:
    print(f"ğŸ‰ ç›®æ¨™é”æˆï¼ç›¸é–¢ä¿‚æ•°0.8+ã‚’å®Ÿç¾: {final_corr:.4f}")
elif final_corr >= 0.7:
    print(f"ğŸ¯ è‰¯å¥½ãªçµæœ: {final_corr:.4f} (ç›®æ¨™0.8ã«æ¥è¿‘)")
elif final_corr >= 0.6:
    print(f"ğŸ“ˆ æ”¹å–„ç¢ºèª: {final_corr:.4f} (ç›®æ¨™0.8ã«å‘ä¸Šä¸­)")
else:
    print(f"âš¡ ç¶™ç¶šæ”¹å–„ä¸­: {final_corr:.4f} (ç›®æ¨™0.8)")

# ===== çµæœå¯è¦–åŒ– =====
print(f"\nğŸ’¾ çµæœã‚’å¯è¦–åŒ–ä¸­...")

fig, axes = plt.subplots(2, 3, figsize=(15, 10))

# å…ƒç”»åƒ
initial_corr_full = np.corrcoef(img1_full.flatten(), img2_full.flatten())[0,1]

axes[0,0].imshow(img1_full, cmap='gray')
axes[0,0].set_title(f'è„³ã‚¹ãƒ©ã‚¤ã‚¹1 (å‚ç…§)')
axes[0,0].axis('off')

axes[0,1].imshow(img2_full, cmap='gray')
axes[0,1].set_title(f'è„³ã‚¹ãƒ©ã‚¤ã‚¹2 (åˆæœŸ)\nç›¸é–¢ä¿‚æ•°: {initial_corr_full:.4f}')
axes[0,1].axis('off')

axes[0,2].imshow(final_transformed, cmap='gray')
axes[0,2].set_title(f'è„³ã‚¹ãƒ©ã‚¤ã‚¹2 (æœ€é©åŒ–å¾Œ)\nç›¸é–¢ä¿‚æ•°: {final_corr:.4f}')
axes[0,2].axis('off')

# å·®åˆ†ç”»åƒ
diff_initial = np.abs(img1_full - img2_full)
diff_final = np.abs(img1_full - final_transformed)

axes[1,0].imshow(diff_initial, cmap='hot')
axes[1,0].set_title(f'åˆæœŸå·®åˆ†ç”»åƒ\nå¹³å‡å·®åˆ†: {np.mean(diff_initial):.4f}')
axes[1,0].axis('off')

axes[1,1].imshow(diff_final, cmap='hot')
axes[1,1].set_title(f'æœ€é©åŒ–å¾Œå·®åˆ†ç”»åƒ\nå¹³å‡å·®åˆ†: {np.mean(diff_final):.4f}')
axes[1,1].axis('off')

# ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤
overlay = np.zeros((img1_full.shape[0], img1_full.shape[1], 3))
overlay[:,:,0] = img1_full  # èµ¤ãƒãƒ£ãƒ³ãƒãƒ«
overlay[:,:,1] = final_transformed  # ç·‘ãƒãƒ£ãƒ³ãƒãƒ«
overlay = np.clip(overlay, 0, 1)

axes[1,2].imshow(overlay)
axes[1,2].set_title(f'ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤è¡¨ç¤º\n(èµ¤:å‚ç…§, ç·‘:ä½ç½®åˆã‚ã›å¾Œ)')
axes[1,2].axis('off')

plt.tight_layout()
plt.suptitle(f'ğŸ§  é«˜é€Ÿé«˜ç²¾åº¦è„³ã‚¹ãƒ©ã‚¤ã‚¹ãƒ¬ã‚¸ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœ\nç›¸é–¢ä¿‚æ•°: {initial_corr_full:.4f} â†’ {final_corr:.4f} (æ”¹å–„: {final_corr-initial_corr_full:+.4f})', 
             fontsize=14, y=0.98)

output_path = 'fast_brain_registration_result.png'
plt.savefig(output_path, dpi=300, bbox_inches='tight')
print(f"ğŸ’¾ {output_path} ä¿å­˜å®Œäº†")

plt.show()

print("=" * 80)
print("ğŸ‰ é«˜é€Ÿé«˜ç²¾åº¦è„³ã‚¹ãƒ©ã‚¤ã‚¹ãƒ¬ã‚¸ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†ï¼")
print("=" * 80)

status_emoji = "ğŸ‰" if final_corr >= 0.8 else "ğŸ¯" if final_corr >= 0.7 else "ğŸ“ˆ" if final_corr >= 0.6 else "âš¡"

print(f"""
ğŸ“Š æœ€çµ‚æˆæœã‚µãƒãƒªãƒ¼:
   ğŸ¯ ç›®æ¨™ç›¸é–¢ä¿‚æ•°: 0.8
   ğŸ“ˆ é”æˆç›¸é–¢ä¿‚æ•°: {final_corr:.4f}
   âš¡ æ”¹å–„å¹…: {final_corr-initial_corr_full:+.4f}
   ğŸ† è¤‡åˆé¡ä¼¼åº¦: {final_composite:.4f}
   ğŸ“Š æ”¹å–„ç‡: {improvement_rate:+.1f}%
   
ğŸ§  å®Ÿè£…æŠ€è¡“:
   âœ“ é«˜é€Ÿç›¸äº’æƒ…å ±é‡è¨ˆç®—
   âœ“ æ®µéšçš„å·®åˆ†é€²åŒ–æœ€é©åŒ–
   âœ“ é©å¿œçš„ç”»åƒå¤‰æ›
   âœ“ é‡ã¿ä»˜ã‘è¤‡åˆãƒ¡ãƒˆãƒªã‚¯ã‚¹
   âœ“ ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«å‡¦ç†
   
{status_emoji} {'ç›®æ¨™é”æˆï¼' if final_corr >= 0.8 else 'ç¶™ç¶šæ”¹å–„ä¸­' if final_corr < 0.8 else 'è‰¯å¥½ãªçµæœ'}
""")

# ã•ã‚‰ãªã‚‹æ”¹å–„ææ¡ˆ
if final_corr < 0.8:
    print(f"""
ğŸ”§ ã•ã‚‰ãªã‚‹æ”¹å–„ã®ãŸã‚ã®ææ¡ˆ:
   1. ã‚ˆã‚Šå¤šãã®æœ€é©åŒ–ã‚¹ãƒ†ãƒƒãƒ—ã®å®Ÿè¡Œ
   2. éç·šå½¢å¤‰æ›ï¼ˆB-splineç­‰ï¼‰ã®é©ç”¨
   3. ãƒãƒ«ãƒãƒ¬ãƒ™ãƒ«ç”»åƒãƒ”ãƒ©ãƒŸãƒƒãƒ‰æœ€é©åŒ–
   4. ç‰¹å¾´ç‚¹ãƒ™ãƒ¼ã‚¹ã®åˆæœŸä½ç½®åˆã‚ã›
   5. ã‚ˆã‚Šé«˜åº¦ãªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®çµ±åˆ
""")
