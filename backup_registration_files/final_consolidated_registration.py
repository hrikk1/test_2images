#!/usr/bin/env python3
"""
çµ±åˆã•ã‚ŒãŸé«˜ç²¾åº¦è„³ã‚¹ãƒ©ã‚¤ã‚¹ç”»åƒãƒ¬ã‚¸ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
ç›®æ¨™: ç›¸é–¢ä¿‚æ•°0.8+ã‚’é”æˆã™ã‚‹
"""

import numpy as np
import cv2
from scipy.optimize import differential_evolution, minimize
from scipy.ndimage import gaussian_filter, map_coordinates
from skimage.metrics import structural_similarity as ssim
from sklearn.metrics import mutual_info_score
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

class AdvancedImageRegistration:
    def __init__(self, verbose=True):
        self.verbose = verbose
        self.best_score = -np.inf
        self.iteration = 0
        
    def load_and_preprocess(self, img1_path, img2_path):
        """ç”»åƒã®èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†"""
        if self.verbose:
            print("ç”»åƒã‚’èª­ã¿è¾¼ã¿ä¸­...")
        
        # ç”»åƒèª­ã¿è¾¼ã¿
        img1 = cv2.imread(img1_path, cv2.IMREAD_GRAYSCALE)
        img2 = cv2.imread(img2_path, cv2.IMREAD_GRAYSCALE)
        
        if img1 is None or img2 is None:
            raise ValueError("ç”»åƒã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
        
        # ãƒã‚¤ã‚ºé™¤å»ã¨ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¼·åŒ–
        img1 = cv2.bilateralFilter(img1, 9, 75, 75)
        img2 = cv2.bilateralFilter(img2, 9, 75, 75)
        
        # CLAHE (Contrast Limited Adaptive Histogram Equalization)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        img1 = clahe.apply(img1)
        img2 = clahe.apply(img2)
        
        # æ­£è¦åŒ–
        img1 = img1.astype(np.float32) / 255.0
        img2 = img2.astype(np.float32) / 255.0
        
        # ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°
        img1 = gaussian_filter(img1, sigma=0.5)
        img2 = gaussian_filter(img2, sigma=0.5)
        
        if self.verbose:
            print(f"ç”»åƒ1å½¢çŠ¶: {img1.shape}, ç”»åƒ2å½¢çŠ¶: {img2.shape}")
        
        return img1, img2
    
    def create_transformation_matrix(self, params):
        """å¤‰æ›è¡Œåˆ—ã®ä½œæˆ"""
        tx, ty, rotation, scale_x, scale_y, shear_x, shear_y = params
        
        # ä¸­å¿ƒç‚¹
        cx, cy = 256, 256  # ç”»åƒä¸­å¿ƒã¨ä»®å®š
        
        # å¤‰æ›è¡Œåˆ—ã®æ§‹ç¯‰
        # 1. ä¸­å¿ƒã¸ã®ç§»å‹•
        T1 = np.array([[1, 0, -cx],
                       [0, 1, -cy],
                       [0, 0, 1]], dtype=np.float32)
        
        # 2. å›è»¢
        cos_r, sin_r = np.cos(rotation), np.sin(rotation)
        R = np.array([[cos_r, -sin_r, 0],
                      [sin_r, cos_r, 0],
                      [0, 0, 1]], dtype=np.float32)
        
        # 3. ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
        S = np.array([[scale_x, 0, 0],
                      [0, scale_y, 0],
                      [0, 0, 1]], dtype=np.float32)
        
        # 4. ã›ã‚“æ–­
        Sh = np.array([[1, shear_x, 0],
                       [shear_y, 1, 0],
                       [0, 0, 1]], dtype=np.float32)
        
        # 5. å¹³è¡Œç§»å‹•
        T2 = np.array([[1, 0, tx],
                       [0, 1, ty],
                       [0, 0, 1]], dtype=np.float32)
        
        # 6. ä¸­å¿ƒã‹ã‚‰ã®ç§»å‹•
        T3 = np.array([[1, 0, cx],
                       [0, 1, cy],
                       [0, 0, 1]], dtype=np.float32)
        
        # å…¨å¤‰æ›ã®åˆæˆ
        M = T3 @ T2 @ Sh @ S @ R @ T1
        return M[:2, :]
    
    def apply_transformation(self, img, params):
        """ç”»åƒã«å¤‰æ›ã‚’é©ç”¨"""
        M = self.create_transformation_matrix(params)
        
        # ã‚¢ãƒ•ã‚£ãƒ³å¤‰æ›ã®é©ç”¨
        transformed = cv2.warpAffine(
            img, M, (img.shape[1], img.shape[0]),
            flags=cv2.INTER_CUBIC,
            borderMode=cv2.BORDER_REFLECT
        )
        
        return transformed
    
    def calculate_mutual_information(self, img1, img2, bins=64):
        """ç›¸äº’æƒ…å ±é‡ã®è¨ˆç®—"""
        # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ãƒ“ãƒ³ã®æº–å‚™
        hist_2d, _, _ = np.histogram2d(
            img1.ravel(), img2.ravel(), bins=bins,
            range=[[0, 1], [0, 1]]
        )
        
        # æ­£è¦åŒ–
        hist_2d = hist_2d + 1e-10  # ã‚¼ãƒ­é™¤ç®—å›é¿
        hist_2d = hist_2d / np.sum(hist_2d)
        
        # å‘¨è¾ºåˆ†å¸ƒ
        px = np.sum(hist_2d, axis=1)
        py = np.sum(hist_2d, axis=0)
        
        # ç›¸äº’æƒ…å ±é‡ã®è¨ˆç®—
        mi = 0.0
        for i in range(bins):
            for j in range(bins):
                if hist_2d[i, j] > 0:
                    mi += hist_2d[i, j] * np.log(hist_2d[i, j] / (px[i] * py[j]))
        
        return mi
    
    def calculate_normalized_mi(self, img1, img2, bins=64):
        """æ­£è¦åŒ–ç›¸äº’æƒ…å ±é‡ã®è¨ˆç®—"""
        mi = self.calculate_mutual_information(img1, img2, bins)
        
        # ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã®è¨ˆç®—
        h1 = -np.sum(np.histogram(img1, bins=bins, range=(0, 1), density=True)[0] * 
                     np.log(np.histogram(img1, bins=bins, range=(0, 1), density=True)[0] + 1e-10)) / bins
        h2 = -np.sum(np.histogram(img2, bins=bins, range=(0, 1), density=True)[0] * 
                     np.log(np.histogram(img2, bins=bins, range=(0, 1), density=True)[0] + 1e-10)) / bins
        
        nmi = 2 * mi / (h1 + h2)
        return nmi
    
    def calculate_edge_correlation(self, img1, img2):
        """ã‚¨ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ç›¸é–¢ã®è¨ˆç®—"""
        # Sobelã‚¨ãƒƒã‚¸æ¤œå‡º
        edge1_x = cv2.Sobel(img1, cv2.CV_64F, 1, 0, ksize=3)
        edge1_y = cv2.Sobel(img1, cv2.CV_64F, 0, 1, ksize=3)
        edge1 = np.sqrt(edge1_x**2 + edge1_y**2)
        
        edge2_x = cv2.Sobel(img2, cv2.CV_64F, 1, 0, ksize=3)
        edge2_y = cv2.Sobel(img2, cv2.CV_64F, 0, 1, ksize=3)
        edge2 = np.sqrt(edge2_x**2 + edge2_y**2)
        
        # ç›¸é–¢è¨ˆç®—
        correlation = np.corrcoef(edge1.ravel(), edge2.ravel())[0, 1]
        return correlation if not np.isnan(correlation) else 0.0
    
    def calculate_gradient_correlation(self, img1, img2):
        """å‹¾é…ãƒ™ãƒ¼ã‚¹ç›¸é–¢ã®è¨ˆç®—"""
        grad1_x, grad1_y = np.gradient(img1)
        grad2_x, grad2_y = np.gradient(img2)
        
        grad1_mag = np.sqrt(grad1_x**2 + grad1_y**2)
        grad2_mag = np.sqrt(grad2_x**2 + grad2_y**2)
        
        correlation = np.corrcoef(grad1_mag.ravel(), grad2_mag.ravel())[0, 1]
        return correlation if not np.isnan(correlation) else 0.0
    
    def calculate_ssim_score(self, img1, img2):
        """SSIM ã‚¹ã‚³ã‚¢ã®è¨ˆç®—"""
        return ssim(img1, img2, data_range=1.0, gaussian_weights=True)
    
    def composite_similarity(self, img1, img2):
        """è¤‡åˆé¡ä¼¼åº¦ã®è¨ˆç®—"""
        # åŸºæœ¬ç›¸é–¢
        corr = np.corrcoef(img1.ravel(), img2.ravel())[0, 1]
        if np.isnan(corr):
            corr = 0.0
        
        # æ­£è¦åŒ–ç›¸äº’æƒ…å ±é‡
        nmi = self.calculate_normalized_mi(img1, img2)
        
        # SSIM
        ssim_score = self.calculate_ssim_score(img1, img2)
        
        # ã‚¨ãƒƒã‚¸ç›¸é–¢
        edge_corr = self.calculate_edge_correlation(img1, img2)
        
        # å‹¾é…ç›¸é–¢
        grad_corr = self.calculate_gradient_correlation(img1, img2)
        
        # é‡ã¿ä»˜ãè¤‡åˆã‚¹ã‚³ã‚¢ï¼ˆæœ€é©åŒ–æ¸ˆã¿é‡ã¿ï¼‰
        composite_score = (
            0.40 * corr +          # åŸºæœ¬ç›¸é–¢
            0.25 * nmi +           # æ­£è¦åŒ–ç›¸äº’æƒ…å ±é‡
            0.20 * ssim_score +    # SSIM
            0.10 * edge_corr +     # ã‚¨ãƒƒã‚¸ç›¸é–¢
            0.05 * grad_corr       # å‹¾é…ç›¸é–¢
        )
        
        return composite_score, {
            'correlation': corr,
            'nmi': nmi,
            'ssim': ssim_score,
            'edge_correlation': edge_corr,
            'gradient_correlation': grad_corr
        }
    
    def objective_function(self, params, fixed_img, moving_img):
        """æœ€é©åŒ–ç›®çš„é–¢æ•°"""
        try:
            # å¤‰æ›é©ç”¨
            transformed = self.apply_transformation(moving_img, params)
            
            # è¤‡åˆé¡ä¼¼åº¦è¨ˆç®—
            score, metrics = self.composite_similarity(fixed_img, transformed)
            
            # æœ€é©åŒ–ã®ãŸã‚è² ã®å€¤ã‚’è¿”ã™ï¼ˆæœ€å°åŒ–ï¼‰
            negative_score = -score
            
            # é€²æ—è¡¨ç¤º
            self.iteration += 1
            if score > self.best_score:
                self.best_score = score
                if self.verbose and self.iteration % 50 == 0:
                    print(f"åå¾© {self.iteration}: æœ€è‰¯ã‚¹ã‚³ã‚¢ = {score:.4f}, ç›¸é–¢ = {metrics['correlation']:.4f}")
            
            return negative_score
            
        except Exception as e:
            if self.verbose:
                print(f"ã‚¨ãƒ©ãƒ¼: {e}")
            return 1000.0  # å¤§ããªãƒšãƒŠãƒ«ãƒ†ã‚£
    
    def multi_stage_optimization(self, fixed_img, moving_img):
        """å¤šæ®µéšæœ€é©åŒ–"""
        if self.verbose:
            print("å¤šæ®µéšæœ€é©åŒ–ã‚’é–‹å§‹...")
        
        # Stage 1: ç²—ã„æ¢ç´¢
        if self.verbose:
            print("Stage 1: ç²—ã„æ¢ç´¢")
        bounds = [
            (-50, 50),    # tx
            (-50, 50),    # ty
            (-0.5, 0.5),  # rotation
            (0.7, 1.3),   # scale_x
            (0.7, 1.3),   # scale_y
            (-0.3, 0.3),  # shear_x
            (-0.3, 0.3)   # shear_y
        ]
        
        result1 = differential_evolution(
            self.objective_function,
            bounds,
            args=(fixed_img, moving_img),
            maxiter=200,
            popsize=20,
            seed=42,
            atol=1e-6,
            tol=1e-6
        )
        
        if self.verbose:
            print(f"Stage 1 å®Œäº†: ã‚¹ã‚³ã‚¢ = {-result1.fun:.4f}")
        
        # Stage 2: ç´°ã‹ã„æ¢ç´¢
        if self.verbose:
            print("Stage 2: ç´°ã‹ã„æ¢ç´¢")
        
        # Stage 1ã®çµæœã‚’ä¸­å¿ƒã¨ã—ãŸç‹­ã„ç¯„å›²ã§æ¢ç´¢
        center = result1.x
        bounds2 = [
            (center[0] - 10, center[0] + 10),
            (center[1] - 10, center[1] + 10),
            (center[2] - 0.1, center[2] + 0.1),
            (center[3] - 0.1, center[3] + 0.1),
            (center[4] - 0.1, center[4] + 0.1),
            (center[5] - 0.1, center[5] + 0.1),
            (center[6] - 0.1, center[6] + 0.1)
        ]
        
        result2 = differential_evolution(
            self.objective_function,
            bounds2,
            args=(fixed_img, moving_img),
            maxiter=150,
            popsize=15,
            seed=123,
            atol=1e-8,
            tol=1e-8
        )
        
        if self.verbose:
            print(f"Stage 2 å®Œäº†: ã‚¹ã‚³ã‚¢ = {-result2.fun:.4f}")
        
        # Stage 3: å±€æ‰€æœ€é©åŒ–
        if self.verbose:
            print("Stage 3: å±€æ‰€æœ€é©åŒ–")
        
        result3 = minimize(
            self.objective_function,
            result2.x,
            args=(fixed_img, moving_img),
            method='L-BFGS-B',
            bounds=bounds2,
            options={'maxiter': 100, 'ftol': 1e-10}
        )
        
        if self.verbose:
            print(f"Stage 3 å®Œäº†: æœ€çµ‚ã‚¹ã‚³ã‚¢ = {-result3.fun:.4f}")
        
        return result3.x
    
    def visualize_results(self, fixed_img, moving_img, optimal_params):
        """çµæœã®å¯è¦–åŒ–"""
        transformed_img = self.apply_transformation(moving_img, optimal_params)
        
        # è¤‡åˆé¡ä¼¼åº¦ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
        final_score, metrics = self.composite_similarity(fixed_img, transformed_img)
        
        # å·®åˆ†ç”»åƒ
        diff_before = np.abs(fixed_img - moving_img)
        diff_after = np.abs(fixed_img - transformed_img)
        
        # ãƒ—ãƒ­ãƒƒãƒˆ
        fig, axes = plt.subplots(3, 3, figsize=(15, 12))
        
        # å…ƒç”»åƒ
        axes[0, 0].imshow(fixed_img, cmap='gray')
        axes[0, 0].set_title('å›ºå®šç”»åƒ')
        axes[0, 0].axis('off')
        
        axes[0, 1].imshow(moving_img, cmap='gray')
        axes[0, 1].set_title('ç§»å‹•ç”»åƒï¼ˆå¤‰æ›å‰ï¼‰')
        axes[0, 1].axis('off')
        
        axes[0, 2].imshow(transformed_img, cmap='gray')
        axes[0, 2].set_title('ç§»å‹•ç”»åƒï¼ˆå¤‰æ›å¾Œï¼‰')
        axes[0, 2].axis('off')
        
        # å·®åˆ†ç”»åƒ
        axes[1, 0].imshow(diff_before, cmap='hot')
        axes[1, 0].set_title('å·®åˆ†ï¼ˆå¤‰æ›å‰ï¼‰')
        axes[1, 0].axis('off')
        
        axes[1, 1].imshow(diff_after, cmap='hot')
        axes[1, 1].set_title('å·®åˆ†ï¼ˆå¤‰æ›å¾Œï¼‰')
        axes[1, 1].axis('off')
        
        # ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤
        overlay = np.zeros((fixed_img.shape[0], fixed_img.shape[1], 3))
        overlay[:, :, 0] = fixed_img
        overlay[:, :, 1] = transformed_img
        axes[1, 2].imshow(overlay)
        axes[1, 2].set_title('ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ï¼ˆèµ¤ï¼šå›ºå®šã€ç·‘ï¼šå¤‰æ›å¾Œï¼‰')
        axes[1, 2].axis('off')
        
        # çµæœè¡¨ç¤º
        result_text = f"""
        æœ€çµ‚çµæœ:
        è¤‡åˆã‚¹ã‚³ã‚¢: {final_score:.4f}
        ç›¸é–¢ä¿‚æ•°: {metrics['correlation']:.4f}
        æ­£è¦åŒ–MI: {metrics['nmi']:.4f}
        SSIM: {metrics['ssim']:.4f}
        ã‚¨ãƒƒã‚¸ç›¸é–¢: {metrics['edge_correlation']:.4f}
        å‹¾é…ç›¸é–¢: {metrics['gradient_correlation']:.4f}
        
        å¤‰æ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:
        å¹³è¡Œç§»å‹•: ({optimal_params[0]:.2f}, {optimal_params[1]:.2f})
        å›è»¢: {np.degrees(optimal_params[2]):.2f}Â°
        ã‚¹ã‚±ãƒ¼ãƒ«: ({optimal_params[3]:.3f}, {optimal_params[4]:.3f})
        ã›ã‚“æ–­: ({optimal_params[5]:.3f}, {optimal_params[6]:.3f})
        """
        
        axes[2, 0].text(0.1, 0.5, result_text, fontsize=10, verticalalignment='center')
        axes[2, 0].axis('off')
        
        # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ æ¯”è¼ƒ
        axes[2, 1].hist(fixed_img.ravel(), bins=50, alpha=0.5, label='å›ºå®šç”»åƒ', color='blue')
        axes[2, 1].hist(transformed_img.ravel(), bins=50, alpha=0.5, label='å¤‰æ›å¾Œç”»åƒ', color='red')
        axes[2, 1].set_title('è¼åº¦ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ')
        axes[2, 1].legend()
        
        # æ•£å¸ƒå›³
        sample_indices = np.random.choice(fixed_img.size, 5000, replace=False)
        axes[2, 2].scatter(
            fixed_img.ravel()[sample_indices], 
            transformed_img.ravel()[sample_indices], 
            alpha=0.1
        )
        axes[2, 2].plot([0, 1], [0, 1], 'r--')
        axes[2, 2].set_xlabel('å›ºå®šç”»åƒã®è¼åº¦')
        axes[2, 2].set_ylabel('å¤‰æ›å¾Œç”»åƒã®è¼åº¦')
        axes[2, 2].set_title(f'è¼åº¦æ•£å¸ƒå›³ (ç›¸é–¢: {metrics["correlation"]:.4f})')
        
        plt.tight_layout()
        plt.savefig('/Users/horiieikkei/Desktop/VS code/final_registration_results.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        return final_score, metrics

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("=== é«˜ç²¾åº¦è„³ã‚¹ãƒ©ã‚¤ã‚¹ç”»åƒãƒ¬ã‚¸ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ ===")
    print("ç›®æ¨™: ç›¸é–¢ä¿‚æ•° 0.8+ ã‚’é”æˆ")
    print()
    
    # ç”»åƒãƒ‘ã‚¹
    img1_path = '/Users/horiieikkei/Desktop/VS code/test2slices/cropped_MMP_109_x4_largest copy.tif'
    img2_path = '/Users/horiieikkei/Desktop/VS code/test2slices/cropped_MMP_110_x4_largest copy.tif'
    
    try:
        # ãƒ¬ã‚¸ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
        registration = AdvancedImageRegistration(verbose=True)
        
        # ç”»åƒèª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†
        fixed_img, moving_img = registration.load_and_preprocess(img1_path, img2_path)
        
        # åˆæœŸçŠ¶æ…‹ã®è©•ä¾¡
        print("åˆæœŸçŠ¶æ…‹ã®è©•ä¾¡ä¸­...")
        initial_score, initial_metrics = registration.composite_similarity(fixed_img, moving_img)
        print(f"åˆæœŸè¤‡åˆã‚¹ã‚³ã‚¢: {initial_score:.4f}")
        print(f"åˆæœŸç›¸é–¢ä¿‚æ•°: {initial_metrics['correlation']:.4f}")
        print()
        
        # å¤šæ®µéšæœ€é©åŒ–å®Ÿè¡Œ
        optimal_params = registration.multi_stage_optimization(fixed_img, moving_img)
        
        print("\n=== æœ€é©åŒ–å®Œäº† ===")
        print("çµæœã‚’å¯è¦–åŒ–ä¸­...")
        
        # çµæœå¯è¦–åŒ–
        final_score, final_metrics = registration.visualize_results(
            fixed_img, moving_img, optimal_params
        )
        
        print(f"\n=== æœ€çµ‚çµæœ ===")
        print(f"è¤‡åˆã‚¹ã‚³ã‚¢: {initial_score:.4f} â†’ {final_score:.4f}")
        print(f"ç›¸é–¢ä¿‚æ•°: {initial_metrics['correlation']:.4f} â†’ {final_metrics['correlation']:.4f}")
        print(f"æ”¹å–„: {final_score - initial_score:.4f}")
        
        # ç›®æ¨™é”æˆåˆ¤å®š
        if final_metrics['correlation'] >= 0.8:
            print("\nğŸ‰ ç›®æ¨™é”æˆï¼ç›¸é–¢ä¿‚æ•° 0.8+ ã‚’é”æˆã—ã¾ã—ãŸï¼")
        else:
            print(f"\nç›®æ¨™ã¾ã§ã‚ã¨ {0.8 - final_metrics['correlation']:.4f} ã§ã™ã€‚")
        
        print(f"\nçµæœç”»åƒãŒä¿å­˜ã•ã‚Œã¾ã—ãŸ: /Users/horiieikkei/Desktop/VS code/final_registration_results.png")
        
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
